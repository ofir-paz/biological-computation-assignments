{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11.3 (6)\n",
    "\n",
    "**question:**\n",
    "\n",
    "*After an individual is chosen to serve as parent, it may either be discarded or returned to the population so that it can be selected again. How does this choice affect selection pressure (for concreteness, consider each selection mechanism separately)?*\n",
    "\n",
    "**answer:**\n",
    "\n",
    "In general, if a successful individual is discarded, the selection pressure is decreased because the same successful individual cannot be selected again, and that leaves the option for lesser individuals to be selected. If the individual is returned to the population, the selection pressure remains high since the same individual will probably be chosen again.\n",
    "\n",
    "For the roulette wheel selection mechanism, if the individual is discarded, the selection pressure is decreased for the reasons mentioned above. If the individual is returned to the population, the selection pressure remains high because the same individual can be chosen again.\n",
    "\n",
    "For the rank-based selection mechanism, it is the same as the last one but the selection pressure is higher because the best individuals are chosen without considering any probability.\n",
    "\n",
    "For the tournament selection mechanism, if the individual is discarded, the selection pressure is decreased lightly because the same individual cannot be chosen again, but the remaining best individuals will still be chosen. If the individual is returned to the population, the selection pressure remains high.\n",
    "\n",
    "For the steady-state selection mechanism, if the individual is discarded, the selection pressure decreases slightly, as the same individual cannot participate in subsequent selection rounds. However, since steady-state selection generally involves replacing only a small portion of the population at each step, the impact on selection pressure is less pronounced compared to other mechanisms. If the individual is returned to the population, the selection pressure remains the same because the most fit individuals have a higher chance of being selected multiple times, maintaining their dominance in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11.5 (19)\n",
    "\n",
    "**question:**\n",
    "\n",
    "*Explain why the niche method lowers the risk of early convergence.*\n",
    "\n",
    "**answer:**\n",
    "\n",
    "The niche method lowers the risk of early convergence by maintaining diversity in the population. The niche method uses a fitness function that considers both the quality of the individual and the diversity of the population. This encourages the population to explore different regions of the search space and prevents the population from converging prematurely to a local optimum. By maintaining diversity, the niche method increases the chances of finding a global optimum and avoids getting stuck in a suboptimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Tuple, Dict, Any, Union, Any, Callable\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# Make sure to install these packages.\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format=\"%(asctime)s - %(name)s.%(levelname)s: %(message)s\",\n",
    "    datefmt=\"%d-%m-%y %H:%M:%S\",\n",
    "    force=True\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation of Conway's Game of Life is fully vectorized and uses [PyTorch](https://pytorch.org/) for the calculation.\n",
    "\n",
    "I've also taken into consideration a few things:\n",
    "\n",
    "1. The finite side of the grid: If the agent goes out of the grid, it will be placed back at the opposite side using circular padding.\n",
    "2. The simulation is batched, so we can simulate multiple runs at once efficiently. Also, all the operations can be done on the GPU if available.\n",
    "3. The simulation keeps the initial state of the grid, so we can evaluate the performance at the end of the simulation. Only the initial and current states are saved - so there is no way to check the stability of the grid within the simulation. I've decided to not check the stability of the grid because it would require much more memory and computation. For example, one of the ways to check the stability of the grid is to save the state of the grid at each step and compare it with the previous states. This would require a lot of memory and computation, especially for large grids and long simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseVecConwaysGOL:\n",
    "    # (curr_state, #neighbours) -> new_state\n",
    "    rules = {\n",
    "        (0, 0): 0,\n",
    "        (0, 1): 0,\n",
    "        (0, 2): 0,\n",
    "        (0, 3): 1,\n",
    "        (0, 4): 0,\n",
    "        (0, 5): 0,\n",
    "        (0, 6): 0,\n",
    "        (0, 7): 0,\n",
    "        (0, 8): 0,\n",
    "\n",
    "        (1, 0): 0,\n",
    "        (1, 1): 0,\n",
    "        (1, 2): 1,\n",
    "        (1, 3): 1,\n",
    "        (1, 4): 0,\n",
    "        (1, 5): 0,\n",
    "        (1, 6): 0,\n",
    "        (1, 7): 0,\n",
    "        (1, 8): 0\n",
    "    }\n",
    "    # k=2\n",
    "    # r=1\n",
    "\n",
    "    def __init__(self, grid: Union[np.ndarray, torch.Tensor]) -> None:\n",
    "        self._orig_grid: np.ndarray = (\n",
    "            grid \n",
    "            if isinstance(grid, np.ndarray) \n",
    "            else grid.detach().cpu().numpy()\n",
    "        )\n",
    "        self._sum_kernel: torch.Tensor = torch.tensor(\n",
    "            [[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32, device=device,\n",
    "        ).unsqueeze(0).unsqueeze(0)\n",
    "        self._set_tensor_rules()\n",
    "        self.reset_grid()\n",
    "\n",
    "    def reset_grid(self) -> None:\n",
    "        self.__step: int = 0\n",
    "        self._pt_grid: torch.Tensor = torch.tensor(\n",
    "            self._orig_grid, dtype=torch.long, device=device\n",
    "        ).view(-1, 1, self._orig_grid.shape[-2], self._orig_grid.shape[-1])\n",
    "    \n",
    "    @property\n",
    "    def grid(self) -> np.ndarray:\n",
    "        return self._pt_grid.squeeze().bool().cpu().numpy()\n",
    "    \n",
    "    @property\n",
    "    def step(self) -> int:\n",
    "        return self.__step\n",
    "    \n",
    "    def _set_tensor_rules(self) -> None:\n",
    "        self._tensor_rules = torch.zeros((2, 9), dtype=torch.long, device=device)\n",
    "        for state, num_neighbours in self.rules:\n",
    "            self._tensor_rules[state, num_neighbours] = self.rules[(state, num_neighbours)]\n",
    "    \n",
    "    def _torch_update(self) -> None:\n",
    "        \"\"\"Updates the grid using PyTorch operations.\"\"\"\n",
    "        padded_pt_grid = F.pad(self._pt_grid, (1, 1, 1, 1), \"circular\")\n",
    "        sum_grid = F.conv2d(padded_pt_grid.float(), self._sum_kernel, padding=0).long().squeeze()\n",
    "        \n",
    "        new_grid_rule_slice = [self._pt_grid.flatten(), sum_grid.flatten()]\n",
    "        new_grid = self._tensor_rules[new_grid_rule_slice].view_as(self._pt_grid)\n",
    "        \n",
    "        self._pt_grid = new_grid\n",
    "    \n",
    "    def update_n(self, n: int) -> None:\n",
    "        for _ in range(n):\n",
    "            self.update()\n",
    "\n",
    "    def update(self) -> None:\n",
    "        \"\"\"Can be overriden to add custom or better update logic.\"\"\"\n",
    "        self._torch_update()\n",
    "        self.__step += 1\n",
    "\n",
    "\n",
    "class VecConwaysGOL(BaseVecConwaysGOL):\n",
    "    \"\"\"Overrides the base class to add plotting capabilities.\"\"\"\n",
    "    def __init__(self, grid: Union[np.ndarray, torch.Tensor]) -> None:\n",
    "        if grid.ndim != 2:\n",
    "            raise ValueError(\"Grid must be a 2D array\")\n",
    "        if grid.shape[0] < 3 or grid.shape[1] < 3:\n",
    "            raise ValueError(\"Grid must be at least 3x3\")\n",
    "        if grid.shape[0] != grid.shape[1]:\n",
    "            raise ValueError(\"Grid must be square\")\n",
    "        super().__init__(grid)\n",
    "    \n",
    "    def update_n(self, n: int, plot: bool = False, plot_every: int = 1, \n",
    "                 sleep_s: float = 0., **plot_kwargs) -> None:\n",
    "        if plot:\n",
    "            if sleep_s < 0:\n",
    "                raise ValueError(\"Sleep must be non-negative\")\n",
    "            if plot_every < 1:\n",
    "                raise ValueError(\"Plot every must be at least 1\")\n",
    "            \n",
    "            for i in range(n):\n",
    "                self.update()\n",
    "                if (i % plot_every) == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    self.plot(**plot_kwargs)\n",
    "                    if sleep_s != 0:\n",
    "                        time.sleep(sleep_s)\n",
    "        else:\n",
    "            for _ in range(n):\n",
    "                self.update()\n",
    "\n",
    "    def plot(self, **kwargs) -> None:\n",
    "        plt.figure(figsize=kwargs.pop(\"figsize\", (10, 10)))\n",
    "        plt.title(f\"Step {self.step}\")\n",
    "        plt.imshow(self.grid * 255, **kwargs)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class BatchedConwaysGOL(BaseVecConwaysGOL):\n",
    "    def __init__(self, grids: Union[np.ndarray, torch.Tensor]) -> None:\n",
    "        if grids.ndim != 3:\n",
    "            raise ValueError(\"Grid must be a 3D array\")\n",
    "        if grids.shape[0] < 3 or grids.shape[1] < 3:\n",
    "            raise ValueError(\"Grids must be at least 3x3\")\n",
    "        if grids.shape[1] != grids.shape[2]:\n",
    "            raise ValueError(\"Grids must be squares\")\n",
    "        super().__init__(grids)\n",
    "\n",
    "    reset_grids = BaseVecConwaysGOL.reset_grid\n",
    "\n",
    "    @property\n",
    "    def grids(self) -> np.ndarray:\n",
    "        return super().grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnownMethuselahs:\n",
    "    \"\"\"Contains some known methuselahs.\"\"\"\n",
    "    R_PENTOMINO: np.ndarray = np.array(\n",
    "        [\n",
    "            [0, 1, 1],\n",
    "            [1, 1, 0],\n",
    "            [0, 1, 0],\n",
    "        ],\n",
    "        dtype=int,\n",
    "    )\n",
    "\n",
    "    ACORN: np.ndarray = np.array(\n",
    "        [\n",
    "            [0, 0, 0, 0, 0, 0, 0],  # Row 5\n",
    "            [0, 0, 0, 0, 0, 0, 0],  # Row 0\n",
    "            [0, 1, 0, 0, 0, 0, 0],  # Row 1\n",
    "            [0, 0, 0, 1, 0, 0, 0],  # Row 2\n",
    "            [1, 1, 0, 0, 1, 1, 1],  # Row 3\n",
    "            [0, 0, 0, 0, 0, 0, 0],  # Row 4\n",
    "            [0, 0, 0, 0, 0, 0, 0],  # Row 6\n",
    "        ],\n",
    "        dtype=int,\n",
    "    )\n",
    "\n",
    "    PI_HEPTOMINO: np.ndarray = np.array(\n",
    "        [\n",
    "            [1, 1, 1],\n",
    "            [1, 0, 1],\n",
    "            [1, 0, 1],\n",
    "        ],\n",
    "        dtype=int,\n",
    "    )\n",
    "\n",
    "    M2513: np.ndarray = np.array(\n",
    "        [\n",
    "            [1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1],\n",
    "            [1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
    "            [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1],\n",
    "            [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0],\n",
    "            [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
    "            [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "            [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
    "            [1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1],\n",
    "            [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
    "            [1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0],\n",
    "            [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
    "        ],\n",
    "        dtype=int\n",
    "    )\n",
    "\n",
    "\n",
    "class Grider:\n",
    "    \"\"\"Utility class to generate grids.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def grid(grd: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Validates and returns a grid.\"\"\"\n",
    "        if not isinstance(grd, np.ndarray):\n",
    "            raise ValueError(\"grid must be a numpy array\")\n",
    "        if grd.ndim != 2:\n",
    "            raise ValueError(\"grid must be a 2D array\")\n",
    "        if grd.shape[0] != grd.shape[1]:\n",
    "            raise ValueError(\"grid must be a square array\")\n",
    "        return grd\n",
    "\n",
    "    @staticmethod\n",
    "    def get_random_grid(size: int, states: List[int] = [0, 1], \n",
    "                        probs: Union[float, List[float]] = 0.7) -> np.ndarray:\n",
    "        if isinstance(probs, float):\n",
    "            probs = [probs]\n",
    "        if len(states) == len(probs) + 1:\n",
    "            probs.append(1 - sum(probs))\n",
    "        if len(states) != len(probs):\n",
    "            raise ValueError(\"States and probs must have the same length\")\n",
    "        \n",
    "        return np.random.choice(states, size=(size, size), p=probs).astype(np.uint8)\n",
    "    \n",
    "    @classmethod\n",
    "    def _enter_center_to_grid(cls, grid: np.ndarray, center: np.ndarray) -> None:\n",
    "        grid = cls.grid(grid)\n",
    "        center = cls.grid(center)\n",
    "        if center.shape[0] > grid.shape[0] or center.shape[1] > grid.shape[1]:\n",
    "            raise ValueError(\"Center must be smaller than grid\")\n",
    "        \n",
    "        grid[\n",
    "            (grid.shape[0] - center.shape[0])//2 : (grid.shape[0] + center.shape[0])//2, \n",
    "            (grid.shape[1] - center.shape[1])//2 : (grid.shape[1] + center.shape[1])//2\n",
    "        ] = center\n",
    "\n",
    "    @classmethod\n",
    "    def get_random_center_grid(cls,\n",
    "            size: int, center_size: int, states: List[int] = [0, 1], \n",
    "            probs: Union[float, List[float]] = 0.7\n",
    "        ) -> np.ndarray:\n",
    "        grid = np.zeros((size, size), dtype=np.uint8)\n",
    "        center = cls.get_random_grid(center_size, states, probs)\n",
    "        cls._enter_center_to_grid(grid, center)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    @classmethod\n",
    "    def get_empty_grid_with_defined_center(cls, size: int, center: np.ndarray) -> np.ndarray:\n",
    "        grid = np.zeros((size, size), dtype=np.uint8)\n",
    "        cls._enter_center_to_grid(grid, center)\n",
    "\n",
    "        return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization - r_pentomino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grider.get_empty_grid_with_defined_center(200, KnownMethuselahs.R_PENTOMINO)\n",
    "gol = VecConwaysGOL(grid)\n",
    "gol.update_n(1400, plot=True, plot_every=11, sleep_s=0., cmap=\"gray\", figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a grid, I've chosen to use the F/I metric ([source](https://conwaylife.com/wiki/Methuselah#Measuring_methuselahs)). This metric is the ratio of the final population to the initial population. The higher the ratio, the better the grid is at sustaining and generating life.\n",
    "\n",
    "The positive of the metric is that we don't need to check the stability of the grid, which would require us to hold a buffer of the previous states. Instead, we can just count the number of cells that are alive at the end and divide it by the number of cells that were alive at the beginning.\n",
    "\n",
    "**Note:** The implementation of the metric is abstract in the way that other fitness functions can be implemented and chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classproperty:\n",
    "    \"\"\"A decorator to create class-level properties.\"\"\"\n",
    "    def __init__(self, fget):\n",
    "        self.fget = fget\n",
    "\n",
    "    def __get__(self, obj, owner):\n",
    "        return self.fget(owner)\n",
    "\n",
    "\n",
    "class MMetric(ABC):\n",
    "    \"\"\"Abstract Base Methuselah Metric class.\"\"\"\n",
    "    def __init_subclass__(cls) -> None:\n",
    "        original_call = cls.__call__\n",
    "\n",
    "        def new_call(self, *args: Any, **kwds: Any) -> Union[float, np.ndarray]:\n",
    "            result = original_call(self, *args, **kwds)\n",
    "            if not isinstance(result, (float, np.ndarray)):\n",
    "                raise RuntimeError(\"Metric result must be a number or numpy array\")\n",
    "            if (\n",
    "                (isinstance(result, float) and result < 0) or\n",
    "                (isinstance(result, np.ndarray) and np.any(result < 0))\n",
    "            ):\n",
    "                raise RuntimeError(\"Metric result must be non-negative\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        cls.__call__ = new_call\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, *args: Any, **kwds: Any) -> Any:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Unspecified Methuselah Metric\"\n",
    "\n",
    "\n",
    "class MMetricFuncs:\n",
    "    \"\"\"Usage: MMetricFuncs.{metric_name} -> MMetric instance with __call__ method.\"\"\"\n",
    "\n",
    "    @classproperty\n",
    "    def FperI(cls) -> MMetric:\n",
    "        class _FperI(MMetric):\n",
    "            def __call__(self, gol: BaseVecConwaysGOL) -> Union[float, np.ndarray]:\n",
    "                \"\"\"F/I: Final population per Initial population\"\"\"\n",
    "                grid, orig_grid = gol.grid, gol._orig_grid\n",
    "                if grid.ndim == 2:\n",
    "                    grid, orig_grid = grid[np.newaxis, ...], orig_grid[np.newaxis, ...]\n",
    "                f = gol.grid.sum(axis=(-2, -1))\n",
    "                i = gol._orig_grid.astype(bool).sum(axis=(-2, -1))\n",
    "\n",
    "                # Avoid division by zero, and if f / i is too small (the grid's \n",
    "                #   population died out), return 1.\n",
    "                # This is to avoid returning 0 as a score so the probability of \n",
    "                #  the gene being selected is not 0.\n",
    "                return np.where(i != 0, np.maximum(f / (i + 1e-8), 1), 0)\n",
    "            \n",
    "            def __repr__(self) -> str:\n",
    "                return \"F/I Metric\"\n",
    "            \n",
    "        return _FperI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next code block shows the implementation of the genetic algorithm framework. The algorithm is implemented as a class with the following methods:\n",
    "- `__init__`: Initializes the genetic algorithm with the specified parameters.\n",
    "- `find`: Runs the genetic algorithm to find the best solution.\n",
    "\n",
    "This framework uses the roulette wheel selection mechanism, and the mating strategy is configured in the child classes, to provide abstraction and flexibility.\n",
    "It uses batched & vectorized implementation that can be run on GPU for a much faster execution.\n",
    "\n",
    "See the documentation of the class for more details of the methods and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMethuselahsFinder(ABC):\n",
    "    \"\"\"\n",
    "    Base Methuselahs Finder class, that uses the roulette wheel selection for mating.\n",
    "    This is an abstract class and should be inherited.\n",
    "    Override the _mate method to define the mating strategy, and the __version__ attribute.\n",
    "    \n",
    "    Attributes:\n",
    "        methuselahs: List[np.ndarray] - List of found Methuselahs.\n",
    "        metric_values - List[np.ndarray] - List of metric values for each generation.\n",
    "\n",
    "    Methods:\n",
    "        __init__: Initialize the MethuselahsFinder.\n",
    "        __repr__: Return the string representation of the MethuselahsFinder.\n",
    "        reset_finder: Reset the finder to the initial state, while keeping saved Methuselahs.\n",
    "        find: Find Methuselahs by maximizing the given metric.\n",
    "        iter: Return the current iteration number (find can be called several times).\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def __version__(cls) -> str:\n",
    "        \"\"\"Version of the Methuselahs Finder\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __init__(\n",
    "            self, pop_size: int, center_side_len: int = 8, \n",
    "            grid_side_len: int = 250, methuselah_min_life: int = 100,\n",
    "            start_live_cell_probs: float = 0.3\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MethuselahsFinder.\n",
    "        \n",
    "        Args:\n",
    "            pop_size: int - Population size for each generation.\n",
    "            center_side_len: int - Side length of the center grid, where the initial live cells are found.\n",
    "            grid_side_len: int - Side length of the grid.\n",
    "            methuselah_min_life: int - Minimum life of a methuselah.\n",
    "            start_live_cell_probs: float - Probability of a cell being alive in the initial grid.\n",
    "        \"\"\"\n",
    "        self.pop_size = pop_size\n",
    "        self.center_side_len = center_side_len\n",
    "        self.grid_side_len = grid_side_len\n",
    "        self.methuselah_min_life = methuselah_min_life\n",
    "        self.start_live_cell_probs = start_live_cell_probs\n",
    "        self.methuselahs: List[np.ndarray] = []\n",
    "        self.reset_finder()\n",
    "        self.__pbar: tqdm\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"MethuselahsFinder_v{self.__version__}(\\n\"\n",
    "            f\"    pop_size={self.pop_size}, \"\n",
    "            f\"center_side_len={self.center_side_len}, \" \n",
    "            f\"grid_side_len={self.grid_side_len}, \"\n",
    "            f\"methuselah_min_life={self.methuselah_min_life}\\n\"\n",
    "            f\"    -------------------------\\n\"\n",
    "            f\"    #found_methuselahs={len(self.methuselahs)} \"\n",
    "            f\"finder_iter={self.iter}\\n\"\n",
    "            f\")\"\n",
    "        )\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _mate(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def reset_finder(self) -> None:\n",
    "        self.candidates = np.array([\n",
    "            Grider.get_random_grid(self.center_side_len, probs=1 - self.start_live_cell_probs) \n",
    "            for _ in range(self.pop_size)\n",
    "        ])\n",
    "        self.metric_values: List[np.ndarray] = []\n",
    "        self.__iter: int = 0\n",
    "\n",
    "    @property\n",
    "    def iter(self) -> int:\n",
    "        return self.__iter\n",
    "\n",
    "    def find(self, iters: int, metric: MMetric, metric_ths: float) -> None:\n",
    "        \"\"\"\n",
    "        Find Methuselahs using the given metric.\n",
    "\n",
    "        Args:\n",
    "            iters: int - Number of iterations to run.\n",
    "            metric: MMetric - Metric to use for finding Methuselahs.\n",
    "            metric_ths: float - Metric threshold to consider a candidate as a Methuselah.\n",
    "        \"\"\"\n",
    "        self.__pbar = tqdm(range(iters), initial=self.iter, total=self.iter + iters, \n",
    "                           desc=\"Finding Methuselahs\")\n",
    "        for _ in self.__pbar:\n",
    "            gol = BatchedConwaysGOL(self._expand_candidates())\n",
    "            gol.update_n(self.methuselah_min_life)\n",
    "            self._update_candidates(gol, metric, metric_ths)\n",
    "            self.__iter += 1\n",
    "\n",
    "    def _expand_candidates(self) -> np.ndarray:\n",
    "        return np.array([\n",
    "            Grider.get_empty_grid_with_defined_center(\n",
    "                self.grid_side_len, candidate\n",
    "            ) for candidate in self.candidates\n",
    "        ])\n",
    "    \n",
    "    def _update_candidates(self, gol: BaseVecConwaysGOL, metric: MMetric, metric_ths: float) -> None:\n",
    "        metric_vals: np.ndarray = metric(gol)\n",
    "        self.metric_values.append(metric_vals)\n",
    "        self.__pbar.set_postfix({\"mean_gen_score\": round(metric_vals.mean(), 2), \n",
    "                                 \"max_gen_score\": round(metric_vals.max(), 2)})\n",
    "\n",
    "        winners_mask = metric_vals >= metric_ths\n",
    "        if np.any(winners_mask):  # Found grid(s) that passed the threshold\n",
    "            # Filter to unique winners\n",
    "            unique_winners_idxs = np.unique(gol._orig_grid[winners_mask], return_index=True, axis=0)[1]\n",
    "            unique_winners = gol._orig_grid[winners_mask][unique_winners_idxs]\n",
    "            unfound_winners_mask = (\n",
    "                (unique_winners[:, np.newaxis, ...] != self.methuselahs)\n",
    "                .any(axis=(-2, -1))\n",
    "                .all(axis=1)\n",
    "            ) if self.methuselahs != [] else np.ones(len(unique_winners), dtype=bool)\n",
    "            if np.any(unfound_winners_mask):  # Found undiscovered methuselah(s)\n",
    "                winner_metrics = metric_vals[winners_mask][unique_winners_idxs][unfound_winners_mask]\n",
    "                self.__pbar.write(f\"Found new methuselah(s) with: {metric}={winner_metrics}\")\n",
    "                self.methuselahs.extend(unique_winners[unfound_winners_mask])\n",
    "\n",
    "        mating_probs = metric_vals / (metric_vals.sum() + 1e-7)\n",
    "        logging.debug(f\"Mating probabilities: {mating_probs}\")\n",
    "        mating_idxs = np.random.choice(np.arange(self.pop_size), size=self.pop_size * 2, p=mating_probs)\n",
    "\n",
    "        new_candidates = np.zeros_like(self.candidates)\n",
    "        for i in range(self.pop_size):\n",
    "            parent1 = self.candidates[mating_idxs[2 * i]]\n",
    "            parent2 = self.candidates[mating_idxs[2 * i + 1]]\n",
    "            child = self._mate(parent1, parent2)\n",
    "            new_candidates[i] = child\n",
    "\n",
    "        self.candidates = new_candidates\n",
    "    \n",
    "    def plot_metric(self, figsize: Tuple[int, int] = (10, 5)) -> None:\n",
    "        \"\"\"Plot mean and max for each generation.\"\"\"\n",
    "        metric_vals = np.array(self.metric_values)\n",
    "        mean_vals = metric_vals.mean(axis=1)\n",
    "        max_vals = metric_vals.max(axis=1)\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(mean_vals, label=\"Mean\", marker=\"o\", linestyle=\"-\", color=\"C0\", linewidth=2, markersize=6)\n",
    "        plt.plot(max_vals, label=\"Max\", marker=\"s\", linestyle=\"--\", color=\"C3\", linewidth=2, markersize=6)\n",
    "        plt.title(\"Generation-wise Metric Values\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Metric Value\")\n",
    "        plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block contains the different mating strategies. The strategies are implemented as child classes of the BaseMethuselahsFinder class and override the `_mate` method to implement the specific mating strategy.\n",
    "\n",
    "I've experimented with the following mating strategies:\n",
    "\n",
    "1. **MethuselahsFinderV1**: This strategy selects a random cut point and combines the parents by taking the first part from the first parent and the second part from the second parent.\n",
    "\n",
    "2. **MethuselahsFinderV2**: This strategy is the same as the first one, but this time the cell in the cut point is selected randomly as a mutation.\n",
    "\n",
    "3. **MethuselahsFinderV3**: This strategy combines the genes of the parents uniformly at random.\n",
    "\n",
    "4. **MethuselahsFinderV4**: Same as v3, but with a mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethuselahsFinderV1(BaseMethuselahsFinder):\n",
    "    __version__ = \"1\"\n",
    "\n",
    "    def _mate(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:\n",
    "        cut = np.random.randint(0, parent1.size)\n",
    "        child = np.zeros(parent1.size)\n",
    "        child[:cut] = parent1.flatten()[:cut]\n",
    "        child[cut:] = parent2.flatten()[cut:]\n",
    "        \n",
    "        return child.reshape(parent1.shape)\n",
    "\n",
    "\n",
    "class MethuselahsFinderV2(BaseMethuselahsFinder):\n",
    "    __version__ = \"2\"\n",
    "\n",
    "    def _mate(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:\n",
    "        cut = np.random.randint(0, parent1.size - 1)\n",
    "        child = np.zeros(parent1.size, dtype=np.uint8)\n",
    "        child[:cut] = parent1.flatten()[:cut]\n",
    "        child[cut] = np.random.randint(0, 2, dtype=np.uint8)\n",
    "        child[cut + 1:] = parent2.flatten()[cut + 1:]\n",
    "        \n",
    "        return child.reshape(parent1.shape)\n",
    "    \n",
    "class MethuselahsFinderV3(BaseMethuselahsFinder):\n",
    "    __version__ = \"3\"\n",
    "\n",
    "    def _mate(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:\n",
    "        p1_mask = np.random.randint(0, 2, parent1.size).astype(bool)\n",
    "        child = np.zeros(parent1.size, dtype=np.uint8)\n",
    "        child[p1_mask] = parent1.flatten()[p1_mask]\n",
    "        child[~p1_mask] = parent2.flatten()[~p1_mask]\n",
    "\n",
    "        return child.reshape(parent1.shape)\n",
    "    \n",
    "class MethuselahsFinderV4(BaseMethuselahsFinder):\n",
    "    __version__ = \"4\"\n",
    "\n",
    "    def __init__(self, mutation_rate: float, *args, **kwds) -> None:\n",
    "        super().__init__(*args, **kwds)\n",
    "        self.mutation_rate = mutation_rate\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            super().__repr__()[:-1] + \n",
    "            f\"    -------------------------\\n\" +\n",
    "            f\"    mutation_rate={self.mutation_rate}\" +\n",
    "            f\"\\n)\"\n",
    "        )\n",
    "    \n",
    "    def _mate(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:\n",
    "        p1_mask = np.random.randint(0, 2, parent1.size).astype(bool)\n",
    "        child = np.zeros(parent1.size, dtype=np.uint8)\n",
    "        child[p1_mask] = parent1.flatten()[p1_mask]\n",
    "        child[~p1_mask] = parent2.flatten()[~p1_mask]\n",
    "        \n",
    "        mutation_mask = np.random.choice(\n",
    "            [0, 1], parent1.size, p=[1 - self.mutation_rate, self.mutation_rate]\n",
    "        )\n",
    "        child[mutation_mask.astype(bool)] = np.random.randint(0, 2, mutation_mask.sum())\n",
    "\n",
    "        return child.reshape(parent1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaseFinderArgs:\n",
    "    pop_size: int\n",
    "    center_side_len: int\n",
    "    grid_side_len: int\n",
    "    methuselah_min_life: int\n",
    "\n",
    "if device == \"cpu\":\n",
    "    finder_args = BaseFinderArgs(\n",
    "        pop_size=15, center_side_len=5, grid_side_len=125, methuselah_min_life=350\n",
    "    ).__dict__\n",
    "    num_iters = 30\n",
    "    metric_ths = 15\n",
    "else:\n",
    "    finder_args = BaseFinderArgs(\n",
    "        pop_size=30, center_side_len=8, grid_side_len=250, methuselah_min_life=1300\n",
    "    ).__dict__\n",
    "    num_iters = 50\n",
    "    metric_ths = 30\n",
    "\n",
    "pprint(finder_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_finder_v1 = MethuselahsFinderV1(**finder_args)\n",
    "logging.info(m_finder_v1)\n",
    "\n",
    "m_finder_v1.find(num_iters, metric=MMetricFuncs.FperI, metric_ths=metric_ths)\n",
    "m_finder_v1.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_finder_v2 = MethuselahsFinderV2(**finder_args)\n",
    "logging.info(m_finder_v2)\n",
    "\n",
    "m_finder_v2.find(num_iters, metric=MMetricFuncs.FperI, metric_ths=metric_ths)\n",
    "m_finder_v2.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_finder_v3 = MethuselahsFinderV3(**finder_args)\n",
    "logging.info(m_finder_v3)\n",
    "\n",
    "m_finder_v3.find(num_iters, metric=MMetricFuncs.FperI, metric_ths=metric_ths)\n",
    "m_finder_v3.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_finder_v4 = MethuselahsFinderV4(0.01, **finder_args)\n",
    "logging.info(m_finder_v4)\n",
    "\n",
    "m_finder_v4.find(num_iters, metric=MMetricFuncs.FperI, metric_ths=metric_ths)\n",
    "m_finder_v4.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found_methuselahs = len(m_finder_v4.methuselahs)\n",
    "\n",
    "if num_found_methuselahs == 0:\n",
    "    logging.info(\"No methuselahs found!\")\n",
    "    logging.info(\"Let's plot the last generation...\")\n",
    "    gol = VecConwaysGOL(m_finder_v4._expand_candidates()[0])\n",
    "\n",
    "else:\n",
    "    logging.info(f\"found #{num_found_methuselahs} methuselahs!\")\n",
    "    logging.info(f\"Let's plot one of them...\")    \n",
    "    gol = VecConwaysGOL(m_finder_v4.methuselahs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gol.update_n(1500, plot=True, plot_every=17, sleep_s=0., cmap=\"gray\", figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "As seen, V1 and V3, both had no mutation, converged to a specific gene - it's easy to see that from the metric plot. V2, was more successful than V1 and V3, as it continued to improve with each generation with its mutations. V4, the best out of all, with a mutation rate of 0.01, was able to find many methuselahs. It is interesting to see that the mutation rate was very low, and still, it was able to find some methuselahs. \n",
    "\n",
    "**Note** in experiments I've made, if the mutation rate was higher, the algorithm diverged and was unable to find any methuselahs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
